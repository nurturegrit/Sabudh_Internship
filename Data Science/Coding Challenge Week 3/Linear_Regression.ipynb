{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69e1a471-ba94-48b6-8d4b-293495c2e5c4",
   "metadata": {},
   "source": [
    "## Machine Learning: Programming Exercise 1\n",
    "### 1 Write a function to generate an m+1 dimensional data set, of size n, consisting of m continuous independent variables (X) and one dependent variable (Y) defined as\n",
    "`yi = xiβ + e`\n",
    "where,\n",
    "\n",
    "* e is a Gaussuan distribution with mean 0 and standard deviation (σ), representing the unexplained\n",
    "variation in Y\n",
    "* β is a random vector of dimensionality m + 1, representing the coefficients of the linear relationship\n",
    "between X and Y, and\n",
    "* ∀i ∈ [1, n], xi0 = 1\n",
    "\n",
    "\n",
    "The function should take the following parameters:\n",
    "* σ: The spread of noise in the output variable\n",
    "* n: The size of the data set\n",
    "* m: The number of indepedent variables\n",
    "\n",
    "\n",
    "Output from the function should be:\n",
    "* X: An n × m numpy array of independent variable values (with a 1 in the first column)\n",
    "* Y : The n × 1 numpy array of output values\n",
    "* β: The random coefficients used to generatre Y from X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42277444-f6c1-4045-9f64-3cad3e6e09d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e89e9b6-4391-46e6-ad09-c1d8ae8e45c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(sigma, n, m, seed=None):\n",
    "    if seed:\n",
    "        np.random.seed(seed)\n",
    "    # Generate X with n rows and m columns\n",
    "    # 1 extra coloum for multplying with B0 Bias\n",
    "    X = np.random.uniform(low=0, high=1, size=(n , m + 1))\n",
    "    # The First column of X should be 1\n",
    "    X[:, 0] = 1\n",
    "    #  A random column_vector with m columns, one for each dependent variable\n",
    "    # 1 Extra column for Bias\n",
    "    Beta_vector = np.random.random(size=(m+1, 1))\n",
    "    # e\n",
    "    e = np.random.normal(loc=0, scale=sigma, size=(n, 1))\n",
    "    # Get Y_vector according to the given formula\n",
    "    y = np.dot(X, Beta_vector) + e\n",
    "    return X, y, Beta_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c439cb16-fbd7-46b0-a11d-f83f1a4b34e1",
   "metadata": {},
   "source": [
    "### 2 Write a function that learns the parameters of a linear regression line given inputs\n",
    "* X: An n × m numpy array of independent variable values\n",
    "* Y : The n × 1 numpy array of output values\n",
    "* k: the number of iteractions (epochs)\n",
    "* τ : the threshold on change in Cost function value from the previous to current iteration\n",
    "* λ: the learning rate for Gradient Descent\n",
    "\n",
    "The function should implement the Gradient Descent algorithm as discussed in class that initialises β with\n",
    "random values and then updates these values in each iteraction by moving in the the direction defined by\n",
    "the partial derivative of the cost function with respect to each of the coefficients. The function should use\n",
    "only one loop that ends after a number of iterations (k) or a threshold on the change in cost function value\n",
    "`(τ )`.\n",
    "\n",
    "The output should be an m + 1 dimensional vector of coefficients and the final cost function value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8668b5b-0455-4314-acfd-7c72633c88a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def learning(X, Y, k, T, L, seed= None):\n",
    "    if seed:\n",
    "        np.random.seed(seed)\n",
    "    def get_gradient(X, Y, B):\n",
    "        n = Y.shape[0]\n",
    "        y_pred = np.dot(X, B)\n",
    "        cost_dot = np.dot(X.T, (y_pred - Y))\n",
    "        gradient = (2/n) * cost_dot\n",
    "        return gradient\n",
    "        \n",
    "    def get_cost(B):\n",
    "        \"\"\"\n",
    "        RMSE as cost_function\n",
    "        \"\"\"\n",
    "        y_pred = np.dot(X, B)\n",
    "        cost = np.sqrt(np.sum((Y - y_pred)**2)/Y.shape[0])\n",
    "        return cost\n",
    "\n",
    "    # Start Model Parameters at random\n",
    "    B = np.random.random(size=(X.shape[1], 1))\n",
    "    prev_cost = get_cost(B)\n",
    "    # k loops\n",
    "    for _ in range(k):\n",
    "        # Perform Gradient Descent\n",
    "        gradient = get_gradient(X, Y, B)\n",
    "        B = B + (L * gradient)\n",
    "        curr_cost = get_cost(B)\n",
    "        if curr_cost - prev_cost < T:\n",
    "            return B, curr_cost\n",
    "        prev_cost = curr_cost\n",
    "    return B, curr_cost        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8703fd0a-5912-4243-8692-66d51d3a8aa4",
   "metadata": {},
   "source": [
    "### 3 Create a report investigating how different values of n and σ impact the ability for your linear regression function to learn the coefficients, `β`, used to generate the output vector `Y `."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88297e0c-bd13-4eb5-b822-2cdfed8531b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_tuple_list = list()\n",
    "# For Finding Eficiency of Model in learning Beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69eabaea-0d99-45d5-b2eb-99fe651268db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_difference_in_beta(B_true, B_pred):\n",
    "    return np.sum(np.square(B_true - B_pred))/len(B_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d688057-0876-4ea5-81bc-c4dd17522186",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = 5\n",
    "n = 100\n",
    "m = 5 # Dependent Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f528095c-4d7b-4d5b-b132-bf32d3eb0f48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100, 1), (100, 6))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, Y, B_true_1 = generate_data(sigma, n, m, 42)\n",
    "# 1 extra column in X for Bias Calculation \n",
    "Y.shape, X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8520c0ec-0fdc-4e63-b9ba-1752b1c76560",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterations\n",
    "k = 40\n",
    "# Learning Rate\n",
    "L = 1.0\n",
    "# Threshold\n",
    "T = np.inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2620a91d-f388-45ac-bb29-38696c4a2b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "B_predicted_1, cost_1 = learning(X=X, Y=Y, k=k, T=T, L=L, seed=42)\n",
    "beta_tuple_list.append((B_true_1, B_predicted_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f762a983-7fd2-419a-85ee-d56d326ffad3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.901492010427813"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bc58f7d2-ff72-4ef6-ad6c-a517916e2bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = 4\n",
    "n = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "99be32dd-1e4d-4b35-a1f4-f6b263c65c89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.76229043784497"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, Y, B_true_2 = generate_data(sigma, n, m, seed=42)\n",
    "# 1 extra column in X for Bias Calculation \n",
    "Y.shape, X.shape\n",
    "\n",
    "B_predicted_2, cost_2 = learning(X=X, Y=Y, k=k, T=T, L=L, seed=42)\n",
    "beta_tuple_list.append((B_true_2, B_predicted_2))\n",
    "cost_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "49b6a11a-1cfe-44a8-8627-76f3eb97ccff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.657513675179832"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigma = 3\n",
    "n = 100\n",
    "X, Y, B_true_3 = generate_data(sigma, n, m, seed=42)\n",
    "\n",
    "B_predicted_3, cost_3 = learning(X=X, Y=Y, k=k, T=T, L=L, seed=42)\n",
    "beta_tuple_list.append((B_true_3, B_predicted_3))\n",
    "cost_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "81b55547-d229-4e73-bac9-28e495b3ed47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.8882302289415316"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigma = 2\n",
    "n = 100\n",
    "X, Y, B_true_4 = generate_data(sigma, n, m)\n",
    "\n",
    "# Let's use Seed so that random factors don't affect us when seeing the effects of n and sigma\n",
    "B_predicted_4, cost_4 = learning(X=X, Y=Y, k=k, T=T, L=L, seed=42)\n",
    "beta_tuple_list.append((B_true_4, B_predicted_4))\n",
    "cost_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4bc7c6f5-f944-4705-bd45-8da6964b6c06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.769655729369683"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigma = 1\n",
    "n = 100\n",
    "X, Y, B_true_5 = generate_data(sigma, n, m)\n",
    "\n",
    "# Let's use Seed so that random factors don't affect us when seeing the effects of n and sigma\n",
    "B_predicted_5, cost_5 = learning(X=X, Y=Y, k=k, T=T, L=L, seed=42)\n",
    "beta_tuple_list.append((B_true_5, B_predicted_5))\n",
    "cost_5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ab198d-f453-4eab-9482-fff7a8d13a89",
   "metadata": {},
   "source": [
    "**I am taking Number of Iterations at 10, because otherwise my function gives an overflow warning during calculations resulting in cost becoming infinity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d237babb-c8b7-4089-ae28-0c4bdf5b1969",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10.901492010427813,\n",
       " 9.76229043784497,\n",
       " 8.657513675179832,\n",
       " 3.8882302289415316,\n",
       " 2.769655729369683)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost_1, cost_2, cost_3, cost_4, cost_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3206ee7f-46e2-4f28-a39e-d8594909cb92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6.228754163505287,\n",
       " 5.35600656321289,\n",
       " 4.549684171901164,\n",
       " 0.8646129568549409,\n",
       " 0.6118753406343145]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lower Value Means the Coefficient learned by Model are closer to real ones\n",
    "[get_difference_in_beta(true, pred) for true, pred in beta_tuple_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f9440a-60f8-447d-b15e-ca5535558106",
   "metadata": {},
   "source": [
    "As per the above observation, we can say that as sigma decreases, the cost_value decreases.\n",
    "And Model's ability to learn beta vector increases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee9806d0-ece3-444b-a4ba-b455ff5d99a8",
   "metadata": {},
   "source": [
    "Report on effect of changing value of n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d6f2c607-e27d-4147-ab9a-3fe5f97bea4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_tuple_list_for_n = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "920402df-a381-4f8d-b381-1ec92a3bd2a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2686115477976918"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 1000\n",
    "X, Y, B_true_1000 = generate_data(sigma, n, m)\n",
    "\n",
    "# Let's use Seed so that random factors don't affect us when seeing the effects of n and sigma\n",
    "B_predicted_1000, cost_1000 = learning(X=X, Y=Y, k=k, T=T, L=L, seed=42)\n",
    "beta_tuple_list_for_n.append((B_true_1000, B_predicted_1000))\n",
    "cost_1000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf645759-7274-4c12-83ed-84dbdd8d0dc0",
   "metadata": {},
   "source": [
    "Increase the the numbers of rows of dataset has given us a notable decrease in cost function. given the same sigma \n",
    "that is sigma = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "83cf5995-5df1-47bb-9024-6e49691d763a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.173817410634527"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 2000\n",
    "X, Y, B_true_2000 = generate_data(sigma, n, m)\n",
    "\n",
    "# Let's use Seed so that random factors don't affect us when seeing the effects of n and sigma\n",
    "B_predicted_2000, cost_2000 = learning(X=X, Y=Y, k=k, T=T, L=L, seed=42)\n",
    "beta_tuple_list_for_n.append((B_true_2000, B_predicted_2000))\n",
    "cost_2000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2adc2a-1468-44be-8b0c-28e61e78230c",
   "metadata": {},
   "source": [
    "After doubling the rows on previous basis, the error has increased significantly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c765cce3-5ca5-4e6f-9506-25cf80f52cb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3057592693545543"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 10000\n",
    "X, Y, B_true_10_4 = generate_data(sigma, n, m)\n",
    "\n",
    "# Let's use Seed so that random factors don't affect us when seeing the effects of n and sigma\n",
    "B_predicted_10_4, cost_10_4 = learning(X=X, Y=Y, k=k, T=T, L=L, seed=42)\n",
    "beta_tuple_list_for_n.append((B_true_10_4, B_predicted_10_4, ))\n",
    "cost_10_4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ee4f81-1851-4149-9ef6-5003d76d78b9",
   "metadata": {},
   "source": [
    "The Cost value has decreased when we increased the n rows exponentially but not comparable to n = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "11227492-3497-4dc1-a801-344581687e0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.8594298456638836"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 100000\n",
    "X, Y, B_true_10_5 = generate_data(sigma, n, m)\n",
    "\n",
    "# Let's use Seed so that random factors don't affect us when seeing the effects of n and sigma\n",
    "B_predicted_10_5, cost_10_5 = learning(X=X, Y=Y, k=k, T=T, L=L, seed=42)\n",
    "beta_tuple_list_for_n.append((B_true_10_5, B_predicted_10_5,))\n",
    "cost_10_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a2838189-3c1b-4a63-932d-389119e9034e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.136143321091605"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 1000000\n",
    "X, Y, B_true_10_6 = generate_data(sigma, n, m)\n",
    "\n",
    "# Let's use Seed so that random factors don't affect us when seeing the effects of n and sigma\n",
    "B_predicted_10_6, cost_10_6 = learning(X=X, Y=Y, k=k, T=T, L=L, seed=42)\n",
    "beta_tuple_list_for_n.append((B_true_10_6, B_predicted_10_6,))\n",
    "cost_10_6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "65887943-dfde-4bfa-99a6-160a7dfaca81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1.2686115477976918, 0),\n",
       " (3.173817410634527, 1),\n",
       " (1.3057592693545543, 2),\n",
       " (1.8594298456638836, 3),\n",
       " (2.136143321091605, 4))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(cost_1000,0), (cost_2000,1), (cost_10_4,2), (cost_10_5,3), (cost_10_6,4),"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7e4d57-b0cd-476f-82da-42d802b05205",
   "metadata": {},
   "source": [
    "In the above observation, we can see that after increase the data rows/samples to 1000,\n",
    "the cost decreased significantly.\n",
    "However, as we exponentially increase the n rows by 10 times each iteration, the cost increases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "40e6b265-f23b-444b-b235-4732b22d2b3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.4451295745106673, 0),\n",
       " (0.8479972271901514, 1),\n",
       " (0.26487284485965173, 2),\n",
       " (0.40125308473266347, 3),\n",
       " (0.48500617333434065, 4)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(get_difference_in_beta(true, pred), n)  for (n, (true, pred)) in enumerate(beta_tuple_list_for_n)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e950a1-54de-4180-8a0f-7aa6744478ac",
   "metadata": {},
   "source": [
    "BUT! , as we can see in element 2, 3; the difference in Actual and Predicted Beta Values is the smaller.\n",
    "even when the cost associated with them is not the lowest cost!\n",
    "\n",
    "So It shows here that model generalises well with these n rows. and the model was overfitted when trained on data \n",
    "with lower n rows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c86816f-9bbc-4343-bd4c-68baa77708cd",
   "metadata": {},
   "source": [
    "Results:\n",
    "* The Model's ability to learn Beta_vector is:\n",
    "     * inversly propotional to the the sigma (standard deviation of e)\n",
    "     * directly propotional to the 'n' number of samples in the generated data.\n",
    "     * In case the model is having more cost value when increasing the n rows, it may that model was overfitted before.\n",
    "     * We cannot fairly conclude that lower cost value of a cost function translates to model learning the coefficients correclty."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eae6839-1e20-443a-912b-6e842e031cf3",
   "metadata": {},
   "source": [
    "**Thanks for reading**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72eb8d4-a84c-4ade-9fa7-168329730af8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
